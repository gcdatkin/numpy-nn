{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "data-science-experiments",
      "language": "python",
      "name": "data-science-experiments"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "NumPyNeuralNetwork.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ata0xdCOX1d0"
      },
      "source": [
        "# Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2JOjPw9dD5E"
      },
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grgefhnrlzmT"
      },
      "source": [
        "random_seed = 2764763\n",
        "np.random.seed(random_seed)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFh6agFKdufV"
      },
      "source": [
        "class InputLayer():\n",
        "    def __init__(self, input_dim):\n",
        "        self.input_dim = input_dim\n",
        "        self.shape = (self.input_dim,)\n",
        "        \n",
        "    def forward(self, input_data):\n",
        "        self.input = input_data\n",
        "        self.output = self.input\n",
        "        return self.output"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFdVTrjah5xf"
      },
      "source": [
        "class DenseLayer():\n",
        "    def __init__(self, input_dim, output_dim, activation, activation_grad):\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.shape = (self.input_dim, self.output_dim)\n",
        "\n",
        "        self.weights = np.random.rand(input_dim, output_dim) - 0.5\n",
        "        self.grad = np.zeros_like(self.weights)\n",
        "\n",
        "        self.activation = activation\n",
        "        self.activation_grad = activation_grad\n",
        "\n",
        "        self.is_output = False\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        self.input = input_data\n",
        "\n",
        "        # Multiply the weights and the input\n",
        "        # Let z be the unactivated output (without the bias)\n",
        "        self.z = np.matmul(np.transpose(self.weights), self.input)\n",
        "        # Apply the activation\n",
        "        self.output = self.activation(self.z)\n",
        "        # Add the bias\n",
        "        if self.is_output == False:\n",
        "            self.output = np.concatenate([np.array([1.0], ndmin=2), self.output], axis=0)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, input_data, weights_data):\n",
        "        self.delta = input_data\n",
        "\n",
        "        if self.is_output == True:\n",
        "            # Just make delta the error if final layer\n",
        "            self.delta = self.output - self.delta\n",
        "\n",
        "        else:\n",
        "            # Matrix multiplication\n",
        "            self.delta = np.matmul(weights_data, self.delta)\n",
        "            # Remove the bias\n",
        "            self.delta = np.delete(self.delta, 0, axis=0)\n",
        "            # \"Undo\" the activation\n",
        "            self.delta = self.delta * self.activation_grad(self.z)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7_LEk2KyjrN"
      },
      "source": [
        "class NeuralNetwork():\n",
        "    def __init__(self, loss, learning_rate):\n",
        "        self.layers = []\n",
        "        self.trained = False\n",
        "\n",
        "        self.loss = loss\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def add(self, layer):\n",
        "        if len(self.layers) > 0:\n",
        "            self.layers[-1].is_output = False\n",
        "        self.layers.append(layer)\n",
        "        self.layers[-1].is_output = True\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.trained == False:\n",
        "            print(\"Model not trained!\")\n",
        "        else:\n",
        "            self.X_pred = X\n",
        "            self.y_pred = []\n",
        "\n",
        "            num_examples = X.shape[0]\n",
        "\n",
        "            for i in range(num_examples):\n",
        "                x = np.expand_dims(np.transpose(X[i, :]), axis=1)\n",
        "                h = x.copy()\n",
        "\n",
        "                for layer in self.layers:\n",
        "                    h = layer.forward(h)\n",
        "\n",
        "                self.y_pred.append(h)\n",
        "\n",
        "            self.y_pred = np.array(self.y_pred, ndmin=2)\n",
        "\n",
        "            return self.y_pred\n",
        "            \n",
        "\n",
        "    def fit(self, X, y, val_data=None, batch_size=32, epochs=10):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.val_data = val_data\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.history = {'loss': [], 'val_loss': []}\n",
        "\n",
        "        num_examples = X.shape[0]\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            total_loss = 0\n",
        "            \n",
        "            for i in range(num_examples):\n",
        "                x = np.expand_dims(np.transpose(X[i, :]), axis=1)\n",
        "\n",
        "                # Feed forward\n",
        "                h = x.copy()\n",
        "                for layer in self.layers:\n",
        "                    h = layer.forward(h)\n",
        "                \n",
        "                training_loss = self.loss(self.y[i], h)\n",
        "                total_loss += training_loss\n",
        "\n",
        "                # Backpropagation\n",
        "                # Accumulate layer gradients\n",
        "                for l in reversed(range(len(self.layers))):\n",
        "                    \n",
        "                    if l > 0:\n",
        "                        if self.layers[l].is_output == True:\n",
        "                            self.layers[l].backward(self.y[i], weights_data=None)\n",
        "\n",
        "                        else:\n",
        "                            self.layers[l].backward(self.layers[l + 1].delta, weights_data=self.layers[l + 1].weights)\n",
        "\n",
        "                        self.layers[l].grad += np.matmul(self.layers[l - 1].output, np.transpose(self.layers[l].delta))\n",
        "\n",
        "            # Get average and update weights\n",
        "            for l in reversed(range(len(self.layers))):\n",
        "                    if l > 0:\n",
        "                        self.layers[l].grad /= num_examples\n",
        "                        self.layers[l].weights -= self.learning_rate * self.layers[l].grad\n",
        "\n",
        "            mean_loss = total_loss / num_examples\n",
        "\n",
        "            if self.val_data == None:\n",
        "                print(\"Epoch\", epoch)\n",
        "                print(\"Training Loss:\", mean_loss)\n",
        "            else:\n",
        "                val_X = self.val_data[0]\n",
        "                val_y = self.val_data[1]\n",
        "                num_val_examples = val_X.shape[0]\n",
        "                total_val_loss = 0\n",
        "                for i in range(num_val_examples):\n",
        "                    val_x = np.expand_dims(np.transpose(val_X[i, :]), axis=1)\n",
        "                    val_h = val_x.copy()\n",
        "                    for layer in self.layers:\n",
        "                        val_h = layer.forward(val_h)\n",
        "                    val_loss = self.loss(val_y[i], h)\n",
        "                    total_val_loss += val_loss\n",
        "                mean_val_loss = total_val_loss / num_val_examples\n",
        "\n",
        "                print(\"Epoch\", epoch)\n",
        "                print(\"Training Loss:\", mean_loss, \"  Validation Loss:\", mean_val_loss)\n",
        "                self.history['loss'].append(mean_loss)\n",
        "                self.history['val_loss'].append(mean_val_loss)\n",
        "\n",
        "        self.trained = True\n",
        "        \n",
        "        self.history['loss'] = np.squeeze(self.history['loss'])\n",
        "        self.history['val_loss'] = np.squeeze(self.history['val_loss'])\n",
        "        \n",
        "        return self.history"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wwOFeboX5TT"
      },
      "source": [
        "# Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwnzJMbDWUqY"
      },
      "source": [
        "# y is true label value, h is prediction\n",
        "def binary_crossentropy(y, h):\n",
        "    return y * (-np.log(h)) + (1 - y) * (-np.log(1 - h))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FTF2OEkX_1M"
      },
      "source": [
        "# Activations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36kuYoZgYJDn"
      },
      "source": [
        "def relu(z):\n",
        "    return z * (z > 0)\n",
        "\n",
        "# Cleaned up the relu gradient\n",
        "# Nice explanation of why its value at 0 doesn't matter:\n",
        "# https://www.quora.com/How-do-we-compute-the-gradient-of-a-ReLU-for-backpropagation\n",
        "def relu_grad(z):\n",
        "    return np.array(z > 0, dtype=np.int)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3rBlNsXYK5f"
      },
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Should be (sigmoid(z)) * (1 - sigmoid(z)), rather than (sigmoid(z)) * (sigmoid(1 - z))\n",
        "def sigmoid_grad(z):\n",
        "    # return sigmoid(z) * sigmoid(1-z)\n",
        "    return sigmoid(z) * (1 - sigmoid(z))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40nHJ89AjCkK"
      },
      "source": [
        "def tanh(z):\n",
        "    return (np.exp(2 * z) - 1) / (np.exp(2 * z) + 1)\n",
        "\n",
        "def tanh_grad(z):\n",
        "    return 1 - (tanh(z) ** 2)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-vAaYIh3DBP"
      },
      "source": [
        "# Processing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8tNlgRUVt6i"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nlINkKkVt64"
      },
      "source": [
        "data = pd.read_csv('/content/indian_liver_patient.csv')\n",
        "original_data = data.copy()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PvawODkVt7Y"
      },
      "source": [
        "## Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo0YTb3UVt7w"
      },
      "source": [
        "## Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvNhO1QYVt7x"
      },
      "source": [
        "def binary_encode(df, column, positive_value):\n",
        "    df = df.copy()\n",
        "    df[column] = df[column].apply(lambda x: 1 if x == positive_value else 0)\n",
        "    return df"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM0JucytVt7k"
      },
      "source": [
        "data['Albumin_and_Globulin_Ratio'] = data['Albumin_and_Globulin_Ratio'].fillna(data['Albumin_and_Globulin_Ratio'].mean())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VILmNxTUVt75"
      },
      "source": [
        "data = binary_encode(data, 'Gender', 'Male')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KVofsFLVt8C"
      },
      "source": [
        "Let's change the labels to 0, 1 instead of 1, 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GCNXwNOVt8D"
      },
      "source": [
        "data = binary_encode(data, 'Dataset', 1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqZXIz4N8xxT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "7a5ec9a6-56f8-4dcc-938a-0ebd7fb1b324"
      },
      "source": [
        "data"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Total_Bilirubin</th>\n",
              "      <th>Direct_Bilirubin</th>\n",
              "      <th>Alkaline_Phosphotase</th>\n",
              "      <th>Alamine_Aminotransferase</th>\n",
              "      <th>Aspartate_Aminotransferase</th>\n",
              "      <th>Total_Protiens</th>\n",
              "      <th>Albumin</th>\n",
              "      <th>Albumin_and_Globulin_Ratio</th>\n",
              "      <th>Dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.1</td>\n",
              "      <td>187</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>10.9</td>\n",
              "      <td>5.5</td>\n",
              "      <td>699</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>7.5</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0.74</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>7.3</td>\n",
              "      <td>4.1</td>\n",
              "      <td>490</td>\n",
              "      <td>60</td>\n",
              "      <td>68</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0.89</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>182</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72</td>\n",
              "      <td>1</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>195</td>\n",
              "      <td>27</td>\n",
              "      <td>59</td>\n",
              "      <td>7.3</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>500</td>\n",
              "      <td>20</td>\n",
              "      <td>34</td>\n",
              "      <td>5.9</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>579</th>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.1</td>\n",
              "      <td>98</td>\n",
              "      <td>35</td>\n",
              "      <td>31</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>580</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>245</td>\n",
              "      <td>48</td>\n",
              "      <td>49</td>\n",
              "      <td>6.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581</th>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>184</td>\n",
              "      <td>29</td>\n",
              "      <td>32</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>582</th>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>216</td>\n",
              "      <td>21</td>\n",
              "      <td>24</td>\n",
              "      <td>7.3</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>583 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age  Gender  Total_Bilirubin  ...  Albumin  Albumin_and_Globulin_Ratio  Dataset\n",
              "0     65       0              0.7  ...      3.3                        0.90        1\n",
              "1     62       1             10.9  ...      3.2                        0.74        1\n",
              "2     62       1              7.3  ...      3.3                        0.89        1\n",
              "3     58       1              1.0  ...      3.4                        1.00        1\n",
              "4     72       1              3.9  ...      2.4                        0.40        1\n",
              "..   ...     ...              ...  ...      ...                         ...      ...\n",
              "578   60       1              0.5  ...      1.6                        0.37        0\n",
              "579   40       1              0.6  ...      3.2                        1.10        1\n",
              "580   52       1              0.8  ...      3.2                        1.00        1\n",
              "581   31       1              1.3  ...      3.4                        1.00        1\n",
              "582   38       1              1.0  ...      4.4                        1.50        0\n",
              "\n",
              "[583 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHpPLTz480jI"
      },
      "source": [
        "y = data['Dataset'].copy()\n",
        "X = data.drop('Dataset', axis=1).copy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "y = np.expand_dims(np.array(y), axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=0)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqr1o4Xz3HYG"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXMgU2uG7pTP"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuKeUiKz7qlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c22527a-8699-42ab-ade5-43924f820c43"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(326, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc0gZDgBF_UO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2423169-fa49-4d14-9b2a-64195e8a3e2d"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(326, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "468lyjwC7yji"
      },
      "source": [
        "model = NeuralNetwork(loss=binary_crossentropy, learning_rate=0.01)\n",
        "\n",
        "model.add(InputLayer(input_dim=10))\n",
        "model.add(DenseLayer(input_dim=10, output_dim=64, activation=relu, activation_grad=relu_grad))\n",
        "model.add(DenseLayer(input_dim=65, output_dim=64, activation=relu, activation_grad=relu_grad))\n",
        "model.add(DenseLayer(input_dim=65, output_dim=1, activation=sigmoid, activation_grad=sigmoid_grad))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MogZulxyohFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a99db4-06c8-4885-ab8d-0f21d5be36ac"
      },
      "source": [
        "for layer in model.layers:\n",
        "    try:\n",
        "        print(layer.weights.shape)\n",
        "        print(layer.is_output)\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 64)\n",
            "False\n",
            "(65, 64)\n",
            "False\n",
            "(65, 1)\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfQWQcs-3QXF"
      },
      "source": [
        "val_data = (X_val, y_val)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N0E7l4N-JSg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0acc3e5-ad07-4cb1-eb87-9dc7a640c357"
      },
      "source": [
        "batch_size=32\n",
        "epochs = 200\n",
        "\n",
        "history = model.fit(X_train, y_train, val_data=val_data, batch_size=batch_size, epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Training Loss: [[2.04875419]]   Validation Loss: [[2.67606518]]\n",
            "Epoch 1\n",
            "Training Loss: [[1.85369474]]   Validation Loss: [[2.42095568]]\n",
            "Epoch 2\n",
            "Training Loss: [[1.67756929]]   Validation Loss: [[2.1821444]]\n",
            "Epoch 3\n",
            "Training Loss: [[1.51959515]]   Validation Loss: [[1.96154604]]\n",
            "Epoch 4\n",
            "Training Loss: [[1.37875078]]   Validation Loss: [[1.75906682]]\n",
            "Epoch 5\n",
            "Training Loss: [[1.25405991]]   Validation Loss: [[1.57545782]]\n",
            "Epoch 6\n",
            "Training Loss: [[1.14567665]]   Validation Loss: [[1.41190626]]\n",
            "Epoch 7\n",
            "Training Loss: [[1.05316566]]   Validation Loss: [[1.26920337]]\n",
            "Epoch 8\n",
            "Training Loss: [[0.97625775]]   Validation Loss: [[1.14789321]]\n",
            "Epoch 9\n",
            "Training Loss: [[0.91440123]]   Validation Loss: [[1.04674582]]\n",
            "Epoch 10\n",
            "Training Loss: [[0.86649865]]   Validation Loss: [[0.96477337]]\n",
            "Epoch 11\n",
            "Training Loss: [[0.83042924]]   Validation Loss: [[0.89976204]]\n",
            "Epoch 12\n",
            "Training Loss: [[0.80346382]]   Validation Loss: [[0.84861684]]\n",
            "Epoch 13\n",
            "Training Loss: [[0.78320025]]   Validation Loss: [[0.80841729]]\n",
            "Epoch 14\n",
            "Training Loss: [[0.76762154]]   Validation Loss: [[0.77658512]]\n",
            "Epoch 15\n",
            "Training Loss: [[0.75528599]]   Validation Loss: [[0.75105137]]\n",
            "Epoch 16\n",
            "Training Loss: [[0.74520408]]   Validation Loss: [[0.73024467]]\n",
            "Epoch 17\n",
            "Training Loss: [[0.73672445]]   Validation Loss: [[0.71307005]]\n",
            "Epoch 18\n",
            "Training Loss: [[0.72939441]]   Validation Loss: [[0.69867995]]\n",
            "Epoch 19\n",
            "Training Loss: [[0.72292265]]   Validation Loss: [[0.6865083]]\n",
            "Epoch 20\n",
            "Training Loss: [[0.71711975]]   Validation Loss: [[0.67609512]]\n",
            "Epoch 21\n",
            "Training Loss: [[0.71185237]]   Validation Loss: [[0.66711906]]\n",
            "Epoch 22\n",
            "Training Loss: [[0.70700779]]   Validation Loss: [[0.65932665]]\n",
            "Epoch 23\n",
            "Training Loss: [[0.70250676]]   Validation Loss: [[0.65250496]]\n",
            "Epoch 24\n",
            "Training Loss: [[0.69831851]]   Validation Loss: [[0.64652512]]\n",
            "Epoch 25\n",
            "Training Loss: [[0.69438709]]   Validation Loss: [[0.64124195]]\n",
            "Epoch 26\n",
            "Training Loss: [[0.69067569]]   Validation Loss: [[0.63655229]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkepdEZ45vLG"
      },
      "source": [
        "np.argmin(history['val_loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcNh5dpQgaVc"
      },
      "source": [
        "epochs_range = range(epochs)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "plt.plot(\n",
        "    epochs_range,\n",
        "    history['loss'],\n",
        "    label=\"Training Loss\"\n",
        ")\n",
        "\n",
        "plt.plot(\n",
        "    epochs_range,\n",
        "    history['val_loss'],\n",
        ")\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.legend()\n",
        "plt.title(\"Loss Over Time\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlPfOMdxmEnc"
      },
      "source": [
        "np.argmin(history['val_loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwOOA3v11ri2"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.array(y_pred > 0.5, dtype=np.int)\n",
        "\n",
        "y_pred = np.squeeze(y_pred)\n",
        "y_true = np.squeeze(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFzb081d15IQ"
      },
      "source": [
        "# Getting accuracy\n",
        "\n",
        "results = (y_true == y_pred)\n",
        "print(np.mean(results))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}